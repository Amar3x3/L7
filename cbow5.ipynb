{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import string\n","import nltk\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def preprocess_text(text):\n","    # Tokenize the text into words\n","    tokens = word_tokenize(text.lower())\n","\n","    # Remove stopwords and punctuation\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word.isalpha() and word not in stop_words and word not in string.punctuation]\n","\n","    return tokens\n","\n","# Sample text for training the CBOW model\n","text = \"Hi my name is Harish.I love to read.I love to sing.Thats all folks\"\n","\n","# Preprocess the text\n","tokens = preprocess_text(text)\n","\n","# Create training data with context and target word\n","training_data = []\n","context_size = 2  # Adjust the context size as needed\n","\n","for i in range(context_size, len(tokens) - context_size):\n","    context = tokens[i - context_size : i] + tokens[i + 1 : i + 1 + context_size]\n","    target = tokens[i]\n","    training_data.append(context + [target])  # Combine context and target into a single list\n","\n","# Define the CBOW model using Word2Vec\n","model_cbow = Word2Vec(sentences=training_data, vector_size=500, window=context_size, sg=0, min_count=1, workers=4)\n","\n","# Training the CBOW model\n","model_cbow.train(training_data, total_examples=len(training_data), epochs=20)\n","\n","# Given two previous and two latter words, predict the target word\n","previous_words = [\"name\", \"Harish\"]\n","latter_words = [\"sing\", \"folks\"]\n","\n","# Use the predict_output_word function from gensim.models.word2vec module\n","predicted_word = model_cbow.predict_output_word(previous_words + latter_words, topn=1)\n","\n","print(f\"Predicted word: {predicted_word}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Il4OWhgbHbJz","executionInfo":{"status":"ok","timestamp":1700375915797,"user_tz":-330,"elapsed":3709,"user":{"displayName":"Harish Bapat","userId":"01261412703411895454"}},"outputId":"062cd898-50f6-469f-bfd9-3864cc5c3f5c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"]},{"output_type":"stream","name":"stdout","text":["Predicted word: [('love', 0.25000066)]\n"]}]},{"cell_type":"code","source":["similar_words = model_cbow.wv.most_similar(predicted_word, topn=5)\n","\n","print(f\"Words most similar to '{predicted_word}':\")\n","for word, similarity in similar_words:\n","    print(f\"{word}: {similarity}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJ8u2oURHde5","executionInfo":{"status":"ok","timestamp":1700296496980,"user_tz":-330,"elapsed":549,"user":{"displayName":"Harish Bapat","userId":"01261412703411895454"}},"outputId":"f6f8ce85-6f6a-48f6-9480-4af74ef36edb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words most similar to 'love':\n","name: 0.006858860608190298\n","hi: -0.04485169053077698\n","folks: -0.05462680757045746\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"d1cmIhS9H80x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700282105226,"user_tz":-330,"elapsed":390,"user":{"displayName":"Harish Bapat","userId":"01261412703411895454"}},"outputId":"2e9e78d3-1b2f-458d-c472-bbb04d1453a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample triplet: [[3, 1], [4, 6], [4, 6], [5, 4], [4, 2], [2, 4], [5, 3], [1, 2], [3, 4], [2, 5], [3, 5], [6, 5], [5, 1], [4, 3], [4, 3], [3, 2], [1, 3], [3, 8], [4, 9], [4, 5], [3, 8], [2, 3], [2, 1], [3, 8], [4, 5], [1, 7], [6, 4], [1, 9], [3, 3], [5, 9], [6, 4], [2, 2], [2, 6], [5, 4], [6, 7], [5, 6]]\n"]}]}]}